# 手写数字识别
## 说明
- 使用parser对参数进行设置
- 使用AverageMeter对损失进行记录
- 代码编写的流程
  - 设置超参数
  - 构建数据集
  - 实现网络结构
  - 完成训练代码
  - 完成测试代码
## 环境
- Windows 10
- Pytorch 3.12
- Python 3.8
## 运行
```js
python train.py --batch-size 4 --lr 1e-3 --epoch 10 --save-path save --log-interval 50 --save-interval 2
```
## 结果
结果以优化器的种类进行分类，训练的batch size都为4，结果如下：
### AdamW
| 网络结构                                    | 学习率  | epoch | ACC   |
|-----------------------------------------|------|-------|-------|
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 2     | 98.20 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 4     | 98.03 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 6     | 97.51 |

Epoch=2时效果最好
### SGD
| 网络结构                                    | 学习率  | epoch | ACC   |
|-----------------------------------------|------|-------|-------|
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 2     | 98.96 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 4     | 98.61 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 6     | 99.16 |
Epoch=6时效果最好


### Adam
| 网络结构                                    | 学习率  | epoch | ACC   |
|-----------------------------------------|------|-------|-------|
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 2     | 95.40 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 4     | 96.54 |
| 2层Conv(k_s:5), 3层FC(512->256->128->10)  | 1e-3 | 6     | 97.84 |

## 参考资料
[利用PyTorch实现基于MNIST数据集的手写数字识别](https://blog.csdn.net/qq_51447496/article/details/136598728)
